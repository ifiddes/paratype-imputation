{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tools.bio import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO/Biostar94573] 2017-11-11 20:11:22 \"Starting JOB at Sat Nov 11 20:11:22 PST 2017 com.github.lindenb.jvarkit.tools.biostar.Biostar94573 version=d31e94729837485c0eeaa8bf00300fee7dd25b88  built=2015-08-15:12-08-53\"\n",
      "[INFO/Biostar94573] 2017-11-11 20:11:22 \"Command Line args : -R Notch2NL_consensus n2nl-100kb-with-consensus.fa\"\n",
      "[INFO/Biostar94573] 2017-11-11 20:11:22 \"Executing as ifiddes@kolossus on Linux 2.6.32-642.11.1.el6.x86_64 amd64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_45-b14\"\n",
      "[INFO/Biostar94573] 2017-11-11 20:11:22 \"Reading from n2nl-100kb-with-consensus.fa\"\n",
      "[INFO/Biostar94573] 2017-11-11 20:11:22 \"format : Fasta\"\n",
      "[INFO/Biostar94573] 2017-11-11 20:11:22 \"Done\"\n",
      "[INFO/Biostar94573] 2017-11-11 20:11:22 \"End JOB status=0 [Sat Nov 11 20:11:22 PST 2017] com.github.lindenb.jvarkit.tools.biostar.Biostar94573 done. Elapsed time: 0.01 minutes.\"\n"
     ]
    }
   ],
   "source": [
    "!java -jar /cluster/home/ifiddes/jvarkit/dist-1.133/biostar94573.jar  -R Notch2NL_consensus n2nl-100kb-with-consensus.fa  > consensus.raw.vcf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import vcf\n",
    "vcf_path = 'consensus.raw.vcf'\n",
    "vcf_recs = list(vcf.Reader(open(vcf_path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vcf_recs = [x for x in vcf_recs if x.is_snp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# construct a list of markers with AB merged\n",
    "r = []\n",
    "from tools.fileOps import *\n",
    "import pandas as pd\n",
    "order = ['NOTCH2NLA', 'NOTCH2NLB', 'NOTCH2NLC', 'NOTCH2NLR', 'NOTCH2']\n",
    "outf = open('snps_only.vcf', 'w')\n",
    "writer = vcf.Writer(outf, vcf.Reader(open(vcf_path)))\n",
    "for v in vcf_recs:\n",
    "    if v.is_indel:\n",
    "        continue\n",
    "    vals = {x.sample : int(x.gt_alleles[0]) for x in v.samples}\n",
    "    vals = [v.POS - 1] + [vals[x] for x in order]\n",
    "    r.append(vals)\n",
    "    writer.write_record(v)\n",
    "outf.close()\n",
    "df = pd.DataFrame(r, columns=['position', 'A', 'B', 'C', 'D', 'N'])\n",
    "df['AB'] = df['A'] + df['B']\n",
    "df = df.drop(['A', 'B'], axis=1)\n",
    "df[['position', 'AB', 'C', 'D', 'N']].set_index('position').to_csv('hg38_features_ab_merge.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# construct a list of markers with AB split\n",
    "r = []\n",
    "from tools.fileOps import *\n",
    "import pandas as pd\n",
    "order = ['NOTCH2NLA', 'NOTCH2NLB', 'NOTCH2NLC', 'NOTCH2NLR', 'NOTCH2']\n",
    "for v in vcf_recs:\n",
    "    if v.is_indel:\n",
    "        continue\n",
    "    vals = {x.sample : int(x.gt_alleles[0]) for x in v.samples}\n",
    "    vals = [v.POS - 1] + [vals[x] for x in order]\n",
    "    r.append(vals)\n",
    "df = pd.DataFrame(r, columns=['position', 'A', 'B', 'C', 'D', 'N'])\n",
    "df[['position', 'A', 'B', 'C', 'D', 'N']].set_index('position').to_csv('hg38_features.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# merge feature sets\n",
    "new_df = pd.read_csv('NA12878_NA19240_NA24385_H9_AB.100kb.features.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['A'] = [1 if x > 0 else 0 for x in df['A']]\n",
    "df['B'] = [1 if x > 0 else 0 for x in df['B']]\n",
    "df['C'] = [1 if x > 0 else 0 for x in df['C']]\n",
    "df['D'] = [1 if x > 0 else 0 for x in df['D']]\n",
    "df['N'] = [1 if x > 0 else 0 for x in df['N']]\n",
    "\n",
    "merged = pd.merge(new_df, df, on='position', how='outer').fillna(0).sort_values('position')\n",
    "merged['position'] = map(int, merged['position'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "merged.set_index('position').to_csv('merged_features.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
