{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "from tools.procOps import *\n",
    "from tools.fileOps import *\n",
    "import itertools\n",
    "import multiprocessing\n",
    "from scipy.special import *\n",
    "from tools.bio import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loc</th>\n",
       "      <th>NAB</th>\n",
       "      <th>NC</th>\n",
       "      <th>ND</th>\n",
       "      <th>NN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>240</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>386</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>393</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   loc  NAB  NC  ND  NN\n",
       "0   56    0   0   0   1\n",
       "1  178    0   0   1   0\n",
       "2  240    0   0   0   1\n",
       "3  386    1   0   0   0\n",
       "4  393    1   0   0   0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sun_df = pd.read_csv('copy_number/hg38_features.txt', sep='\\t')\n",
    "sun_df.columns = ['loc', 'NAB', 'NC', 'ND', 'NN']\n",
    "sun_df['NAB'] = [1 if x > 0 else 0 for x in sun_df['NAB']]\n",
    "sun_df['NC'] = [1 if x > 0 else 0 for x in sun_df['NC']]\n",
    "sun_df['ND'] = [1 if x > 0 else 0 for x in sun_df['ND']]\n",
    "sun_df['NN'] = [1 if x > 0 else 0 for x in sun_df['NN']]\n",
    "sun_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# remove bad positions\n",
    "bad_positions = set([48646, 75180, 17731, 43539, 2967, 54815, 64033, 89900, 66088, 68137, 90156, 85939, 87309, 70198, 54452, 1594, 77455, 8253, 73792, 7776, 60995, 44613, 96353, 24138, 48718, 13391, 47185, 24659, 29269, 13913, 23133, 68191, 29280, 69729, 1635, 88677, 10513, 74860, 54893, 90226, 57973, 74358, 58487, 82556, 10517, 76419, 59524, 74373, 41094, 8843, 63630, 74383, 5267, 57493, 12439, 35992, 85862, 3235, 48297, 68722, 24754, 74420, 95925, 7356, 7871, 38598, 18209, 5841, 39122, 67796, 68309, 94430, 6370, 93478, 49894, 37095, 52457, 16620, 92397, 60142, 76015, 41712, 93480, 41716, 54006, 22990, 48376, 16597, 92418, 40711, 93484, 63242, 26380, 898, 92431, 29144, 49941, 43799, 48409, 91419, 90398, 92448, 25889, 64803, 10534, 24359, 39720, 46889, 93482, 25900, 93486, 76080, 20276, 78646, 53056, 86339, 76104, 41186, 14670, 67410, 23382, 83803, 17245, 17760, 63844, 88806, 74086, 26983, 46953, 88039, 878, 12655, 16345, 7957, 38774, 50409, 386, 1496, 41878, 66952, 393, 53655, 60815, 15250, 58691, 41454, 64406, 70039, 2459, 11679, 86432, 34203, 94628, 2469, 72614, 84903, 74664, 42921, 29100, 40370, 37299, 78266, 9149, 61385, 65996, 29133, 85454, 89553, 45522, 21459, 27096, 47065, 51164, 76769, 8674, 85806, 56292, 88037, 89169, 47080, 54766, 30196, 70649, 70651, 31230, 92159])\n",
    "sun_df = sun_df[~sun_df['loc'].isin(bad_positions)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load parsed pileups\n",
    "files = glob('/hive/users/ifiddes/simons_normals/96kb_consensus/*.parsed_pileup.txt')\n",
    "dfs = {}\n",
    "for f in files:\n",
    "    n = os.path.basename(f).split('.')[0]\n",
    "    dfs[n] = pd.read_csv(f, sep='\\t', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load C/D copy number estimates\n",
    "\n",
    "files = glob('/hive/users/ifiddes/simons_normals/*.filtered.txt')\n",
    "\n",
    "from collections import Counter\n",
    "def convert(x):\n",
    "    x = x.split(':')\n",
    "    n, v = x\n",
    "    v = int(v)\n",
    "    return n, v\n",
    "\n",
    "copy_number = {}\n",
    "for x in files:\n",
    "    n = os.path.basename(x).split('.')[0]\n",
    "    l = open(x).next().rstrip().split()\n",
    "    c = []\n",
    "    for x in l[2:4]:\n",
    "        _, v = convert(x)\n",
    "        c.append(v)\n",
    "    copy_number[n] = c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# filter dataframes for C = 2 and D = 2\n",
    "# also filter for informative positions\n",
    "filtered_dfs = {}\n",
    "for n, df in dfs.iteritems():\n",
    "    c = copy_number[n]\n",
    "    if sum(c) != 4:\n",
    "        continue\n",
    "    df_m = df.merge(sun_df, on='loc')\n",
    "    df_m = df_m[df_m['loc'].isin(sun_df['loc'])]\n",
    "    filtered_dfs[n] = df_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "useful_positions = set.intersection(*[set(x['loc']) for x in filtered_dfs.itervalues()])\n",
    "filtered_sun_df = sun_df[sun_df['loc'].isin(useful_positions)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = []\n",
    "l = []\n",
    "actual_alt = []\n",
    "actual_ref = []\n",
    "\n",
    "for n, df_m in filtered_dfs.iteritems():\n",
    "    for _, s in df_m.iterrows():\n",
    "        if s.coverage >= 10 and s.ratio >= 0.01:\n",
    "            num_alt = 4 * s.NAB + 2 * s.NC + 2 * s.ND + 2 * s.NN  # number of alt paratypes\n",
    "            num_ref = 10 - num_alt  # valid because these are all 4-2-2-2\n",
    "            k.append(num_alt)\n",
    "            l.append(num_ref)\n",
    "            actual_alt.append(s.alt_count)\n",
    "            actual_ref.append(s.ref_count)\n",
    "        else:\n",
    "            k.append(0)\n",
    "            l.append(0)\n",
    "            actual_alt.append(0)\n",
    "            actual_ref.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = np.array(k).reshape(len(filtered_dfs), df_m.shape[0]).T\n",
    "l = np.array(l).reshape(len(filtered_dfs), df_m.shape[0]).T\n",
    "actual_alt = np.array(actual_alt).reshape(len(filtered_dfs), df_m.shape[0]).T\n",
    "actual_ref = np.array(actual_ref).reshape(len(filtered_dfs), df_m.shape[0]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# all proposed genotypes\n",
    "def construct_C(max_n=12, min_n=8, k=4):\n",
    "    list1=np.arange(0,6)\n",
    "    r = []\n",
    "    for i in itertools.product(list1,repeat=k):\n",
    "        if min_n <= np.sum(i) <= max_n:\n",
    "            r.append(i)\n",
    "    return np.array(r)\n",
    "\n",
    "C = construct_C()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# number of haplotypes that are expected to be alt in each C\n",
    "ft = filtered_sun_df.set_index('loc').T\n",
    "alt_options = np.dot(C, ft)\n",
    "\n",
    "# ref options -- first construct vector of total number of paratypes in each row of C\n",
    "tot = C.sum(axis=1)\n",
    "tot = np.array([tot] * alt_options.shape[1]).T # turn into total matrix\n",
    "ref_options = tot - alt_options  # remove alt to get ref counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#precompute tot\n",
    "tot = np.nansum(actual_alt, axis=1) + np.nansum(actual_ref, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a_matrix = []\n",
    "b_matrix = []\n",
    "for a, b in zip(alt_options, ref_options):\n",
    "    alt = (np.divide(k, np.vstack(a + 0.1)) * actual_alt).sum(axis=1)\n",
    "    ref = (np.divide(l, np.vstack(b + 0.1)) * actual_ref).sum(axis=1)\n",
    "    for i, (x, y) in enumerate(zip(alt, ref)):\n",
    "        if np.isnan(x):\n",
    "            alt[i] = 0.01 * y\n",
    "        elif np.isnan(y):\n",
    "            ref[i] = 0.01 * x\n",
    "        assert not np.isnan(alt[i])\n",
    "    u = alt / (alt + ref)\n",
    "    a = u * (tot - 1)\n",
    "    b = (1 - u) * (tot -1 )\n",
    "    a_matrix.append(a)\n",
    "    b_matrix.append(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a_matrix = np.array(a_matrix)\n",
    "b_matrix = np.array(b_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = []\n",
    "n = []\n",
    "target_coverage = 200\n",
    "for _, s in filtered_sun_df.iterrows():\n",
    "    x = (2.0 * s.NAB + s.NC + s.ND + s.NN) / 10 * target_coverage\n",
    "    y = target_coverage - x\n",
    "    m.append(x)\n",
    "    n.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test\n",
    "\n",
    "r_values = []\n",
    "for a, b in zip(a_matrix, b_matrix):\n",
    "    r_values.append(np.sum(betaln(m + a, n + b) - betaln(a, b)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r_map = {i: x for i, x in enumerate(r_values)}\n",
    "best_index, score = sorted(r_map.iteritems(), key=lambda x: x[1])[-1]\n",
    "best_haps = C[best_index]\n",
    "ordered = sorted(r_map.iteritems(), key=lambda x: x[1])[-10:][::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log odds: -79588.8003979\n",
      "\n",
      "results: \n",
      "NAB: 4\n",
      "NC: 2\n",
      "ND: 3\n",
      "NN: 3\n",
      "NAB NC ND NN\n",
      "top 10 hits:\n",
      "1: [array([4, 2, 3, 3]), 527, -79588.800397898915]\n",
      "2: [array([4, 2, 2, 3]), 522, -79737.745429188799]\n",
      "3: [array([3, 2, 2, 2]), 389, -79902.636472890124]\n",
      "4: [array([3, 2, 2, 3]), 390, -80039.282238943968]\n",
      "5: [array([3, 1, 2, 2]), 363, -80048.964327161419]\n",
      "6: [array([4, 2, 3, 2]), 526, -80063.855637273955]\n",
      "7: [array([4, 2, 2, 4]), 523, -80281.622242225538]\n",
      "8: [array([3, 2, 3, 2]), 395, -80294.668470365548]\n",
      "9: [array([4, 2, 2, 2]), 521, -80497.698168314644]\n",
      "10: [array([5, 2, 2, 3]), 638, -80532.726430768322]\n"
     ]
    }
   ],
   "source": [
    "print 'log odds: {}'.format(score)\n",
    "print ''\n",
    "print 'results: '\n",
    "for x, y in zip(filtered_sun_df.columns[1:], best_haps):\n",
    "    if y > 0:\n",
    "        print '{}: {}'.format(x, y)\n",
    "\n",
    "print ' '.join(filtered_sun_df.columns[1:])\n",
    "print 'top 10 hits:'\n",
    "for i, x in enumerate([[C[pos], pos, val] for pos, val in ordered], 1):\n",
    "    print '{}: {}'.format(i, x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## test old R on these features\n",
    "\n",
    "Ct = C.T\n",
    "\n",
    "num = np.dot(filtered_sun_df.set_index('loc'), Ct)\n",
    "denom = np.sum(Ct, axis=0)\n",
    "S = (1.0 + num) / (2.0 + denom)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "S_log = np.log(S)\n",
    "S_inv = np.log(1 - S)\n",
    "# calculate the masking matrix based on deviance\n",
    "# M is the number of alt reads, N is the number of ref reads\n",
    "R = (np.dot(np.array(m) + 10, S_log) + np.dot(np.array(n) + 10, S_inv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log odds: -99419.4314475\n",
      "\n",
      "results: \n",
      "NAB: 5\n",
      "NC: 3\n",
      "ND: 2\n",
      "NN: 2\n",
      "NAB NC ND NN\n",
      "top 10 hits:\n",
      "1: [array([5, 3, 2, 2]), 656, -99419.431447459021]\n",
      "2: [array([5, 3, 3, 1]), 658, -99861.389458721271]\n",
      "3: [array([4, 4, 2, 2]), 564, -99875.661392076465]\n",
      "4: [array([5, 3, 2, 1]), 655, -99881.558633255278]\n",
      "5: [array([5, 4, 2, 1]), 668, -99911.625945815176]\n",
      "6: [array([4, 3, 2, 1]), 544, -100000.17029657327]\n",
      "7: [array([4, 3, 2, 2]), 545, -100007.88553305517]\n",
      "8: [array([5, 4, 1, 2]), 666, -100078.80157080464]\n",
      "9: [array([5, 3, 1, 2]), 652, -100136.36060544752]\n",
      "10: [array([4, 4, 2, 1]), 563, -100262.35489976255]\n"
     ]
    }
   ],
   "source": [
    "R_map = {i: x for i, x in enumerate(R)}\n",
    "best_index, score = sorted(R_map.iteritems(), key=lambda x: x[1])[-1]\n",
    "best_haps = C[best_index]\n",
    "ordered = sorted(R_map.iteritems(), key=lambda x: x[1])[-10:][::-1]\n",
    "print 'log odds: {}'.format(score)\n",
    "print ''\n",
    "print 'results: '\n",
    "for x, y in zip(filtered_sun_df.columns[1:], best_haps):\n",
    "    if y > 0:\n",
    "        print '{}: {}'.format(x, y)\n",
    "\n",
    "print ' '.join(filtered_sun_df.columns[1:])\n",
    "print 'top 10 hits:'\n",
    "for i, x in enumerate([[C[pos], pos, val] for pos, val in ordered], 1):\n",
    "    print '{}: {}'.format(i, x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sanity check -- synthetic data\n",
    "\n",
    "syn_k = []\n",
    "syn_l = []\n",
    "syn_alt = []\n",
    "syn_ref = []\n",
    "target_coverage = 100\n",
    "for i, (_, s) in enumerate(filtered_sun_df[:3].iterrows()):\n",
    "    num_alt = 1 if i  == 0 else 2\n",
    "    #num_alt = 4 * s.NAB + 2 * s.NC + 2 * s.ND + 2 * s.NN\n",
    "    num_ref = 10 - num_alt\n",
    "    syn_k.append([num_alt] * 2)\n",
    "    syn_l.append([num_ref] * 2)\n",
    "    tmp_alt = target_coverage * 1.0 * num_alt / 10\n",
    "    syn_alt.append([tmp_alt] * 2)\n",
    "    syn_ref.append([target_coverage - tmp_alt] * 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "syn_k = np.array(syn_k).astype(float)\n",
    "syn_l = np.array(syn_l).astype(float)\n",
    "syn_alt = np.array(syn_alt).astype(float)\n",
    "syn_ref = np.array(syn_ref).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# all proposed genotypes\n",
    "C = construct_C(4,4,2)\n",
    "\n",
    "f = np.array([[1,0],[0,1],[0,1]])\n",
    "\n",
    "alt_options = np.dot(C, f.T)\n",
    "\n",
    "# ref options -- first construct vector of total number of paratypes in each row of C\n",
    "tot = C.sum(axis=1)\n",
    "tot = np.array([tot] * alt_options.shape[1]).T # turn into total matrix\n",
    "ref_options = tot - alt_options  # remove alt to get ref counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 840,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#precompute tot\n",
    "tot = np.nansum(syn_alt, axis=1) + np.nansum(syn_ref, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 873,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a_matrix = []\n",
    "b_matrix = []\n",
    "for a, b in zip(alt_options, ref_options):\n",
    "    alt = (k * syn_alt).sum(axis=1) * 1.0 / a\n",
    "    ref = (l * syn_ref).sum(axis=1) * 1.0 / b\n",
    "    for i, (x, y) in enumerate(zip(alt, ref)):\n",
    "        if np.isinf(x):\n",
    "            alt[i] = 0.01 * y\n",
    "        elif np.isinf(y):\n",
    "            ref[i] = 0.01 * x\n",
    "        assert not np.isinf(alt[i])\n",
    "    u = alt / (alt + ref)\n",
    "    a = u * (tot - 1)\n",
    "    b = (1 - u) * (tot -1 )\n",
    "    a_matrix.append(a)\n",
    "    b_matrix.append(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 874,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a_matrix = np.array(a_matrix)\n",
    "b_matrix = np.array(b_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 875,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coverage: 100\n",
      "A_{0,0}: 1.9702970297\n",
      "B_{0,0}: 197.02970297\n"
     ]
    }
   ],
   "source": [
    "print 'coverage: {}'.format(target_coverage)\n",
    "print 'A_{{0,0}}: {}'.format(a_matrix[0][0])\n",
    "print 'B_{{0,0}}: {}'.format(b_matrix[0][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 876,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test\n",
    "m = np.array([[10, 10, 10]])\n",
    "n = np.array([[90, 90, 90]])\n",
    "r_values = []\n",
    "for a, b in zip(a_matrix, b_matrix):\n",
    "    r_values.append(np.sum(betaln(m + a, n + b) - betaln(a, b)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 877,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r_map = {i: x for i, x in enumerate(r_values)}\n",
    "best_index, score = sorted(r_map.iteritems(), key=lambda x: x[1])[-1]\n",
    "best_haps = C[best_index]\n",
    "ordered = sorted(r_map.iteritems(), key=lambda x: x[1])[-10:][::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 878,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log odds: -106.641161414\n",
      "\n",
      "results: \n",
      "NAB: 2\n",
      "NC: 2\n",
      "NAB NC ND NN\n",
      "top 10 hits:\n",
      "1: [array([2, 2]), 2, -106.64116141427075]\n",
      "2: [array([3, 1]), 3, -109.8657092331448]\n",
      "3: [array([1, 3]), 1, -110.33930959783766]\n",
      "4: [array([4, 0]), 4, -255.49329274306922]\n",
      "5: [array([0, 4]), 0, -390.63856659581404]\n"
     ]
    }
   ],
   "source": [
    "print 'log odds: {}'.format(score)\n",
    "print ''\n",
    "print 'results: '\n",
    "for x, y in zip(filtered_sun_df.columns[1:], best_haps):\n",
    "    if y > 0:\n",
    "        print '{}: {}'.format(x, y)\n",
    "\n",
    "print ' '.join(filtered_sun_df.columns[1:])\n",
    "print 'top 10 hits:'\n",
    "for i, x in enumerate([[C[pos], pos, val] for pos, val in ordered], 1):\n",
    "    print '{}: {}'.format(i, x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# feature matrix -- 1 A feature and 2 B features\n",
    "f = np.array([[1, 0],\n",
    "             [0, 1],\n",
    "             [0, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 919,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 2 synthetic genomes, rows are features \n",
    "# both synthetic genomes therefore are expected to have 1 copy of A and 2 copies of B\n",
    "k = np.array([[1, 1],\n",
    "             [2, 2],\n",
    "             [2, 2]])\n",
    "k = k.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 920,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# and therefore we expect to see 9 copies of ref in A features and 8 in B features\n",
    "l = np.array([[9, 9],\n",
    "             [8, 8],\n",
    "             [8, 8]])\n",
    "l = l.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 921,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# setting coverage to 10, in our idealized scenario, actualAlt and actualRef are 10 * k and 10 * l \n",
    "actual_alt = k * 10\n",
    "actual_ref = l * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 938,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k_i: [2 2 2]\n",
      "\n",
      "l_i: [8 8 8]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# let us propose the haplotype [2,2]\n",
    "c = np.array([2, 2])\n",
    "k_i = np.sum(c * f, axis=1)\n",
    "l_i = 10 - k_i\n",
    "print 'k_i: {}\\n'.format(K)\n",
    "print 'l_i: {}\\n'.format(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 939,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 10.  40.  40.]\n"
     ]
    }
   ],
   "source": [
    "# alt\n",
    "alt = (k * actual_alt).sum(axis=1) * 1.0 / k_i\n",
    "print alt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 940,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 202.5  160.   160. ]\n"
     ]
    }
   ],
   "source": [
    "# ref\n",
    "ref = (l * actual_ref).sum(axis=1) * 1.0 / l_i\n",
    "print ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 941,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u: [ 0.04705882  0.2         0.2       ]\n",
      "a: [  9.36470588  39.8         39.8       ]\n",
      "b: [ 189.63529412  159.2         159.2       ]\n"
     ]
    }
   ],
   "source": [
    "u = alt / (alt + ref)\n",
    "print 'u: {}'.format(u)\n",
    "a = u * (tot - 1)\n",
    "print 'a: {}'.format(a)\n",
    "b = (1 - u) * (tot  - 1)\n",
    "print 'b: {}'.format(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 942,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fake data that matches the expected haplotype of [1, 2]\n",
    "m = np.array([[10, 20, 20]])\n",
    "n = np.array([[90, 80, 80]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 943,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-134.809528911\n"
     ]
    }
   ],
   "source": [
    "# calculate r\n",
    "r = np.sum(betaln(m + a, n + b) - betaln(a, b))\n",
    "print r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 950,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-133.20237652\n"
     ]
    }
   ],
   "source": [
    "# repeat this for the true haplotype of [1, 2]\n",
    "c = np.array([1, 2])\n",
    "k_i = np.sum(c * f, axis=1)\n",
    "l_i = 10 - k_i\n",
    "alt = (k * actual_alt).sum(axis=1) * 1.0 / k_i\n",
    "ref = (l * actual_ref).sum(axis=1) * 1.0 / l_i\n",
    "u = alt / (alt + ref)\n",
    "a = u * (tot - 1)\n",
    "b = (1 - u) * (tot  - 1)\n",
    "r = np.sum(betaln(m + a, n + b) - betaln(a, b))\n",
    "print r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 984,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C (all proposed haplotypes):\n",
      "[[0 3]\n",
      " [1 2]\n",
      " [2 1]\n",
      " [3 0]]\n",
      "\n",
      "all_k (each row is a proposed haplotype each column is a feature):\n",
      "[[0 3 3]\n",
      " [1 2 2]\n",
      " [2 1 1]\n",
      " [3 0 0]]\n",
      "\n",
      "all_l (each row is a proposed haplotype each column is a feature):\n",
      "[[10  7  7]\n",
      " [ 9  8  8]\n",
      " [ 8  9  9]\n",
      " [ 7 10 10]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# repeat this for all possible haplotypes, in matrix form\n",
    "\n",
    "# all proposed genotypes\n",
    "C = np.array([[0, 3],\n",
    "             [1, 2],\n",
    "             [2, 1],\n",
    "             [3, 0]])\n",
    "all_k = np.dot(C, f.T)\n",
    "all_l = 10 - all_k\n",
    "print 'C (all proposed haplotypes):\\n{}\\n'.format(C)\n",
    "\n",
    "print 'all_k (each row is a proposed haplotype each column is a feature):\\n{}\\n'.format(all_k)\n",
    "\n",
    "print 'all_l (each row is a proposed haplotype each column is a feature):\\n{}\\n'.format(all_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 985,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 200.  200.  200.]\n"
     ]
    }
   ],
   "source": [
    "#precompute tot\n",
    "tot = np.nansum(syn_alt, axis=1) + np.nansum(syn_ref, axis=1)\n",
    "print tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 989,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alt/ref ratio for a = [  1.97029703  25.32727273  25.32727273] and b = [ 197.02970297  173.67272727  173.67272727]:\n",
      "[ 0.01        0.14583333  0.14583333]\n",
      "alt/ref ratio for a = [ 19.9  39.8  39.8] and b = [ 179.1  159.2  159.2]:\n",
      "[ 0.11111111  0.25        0.25      ]\n",
      "alt/ref ratio for a = [  9.36470588  71.64        71.64      ] and b = [ 189.63529412  127.36        127.36      ]:\n",
      "[ 0.04938272  0.5625      0.5625    ]\n",
      "alt/ref ratio for a = [ 5.572       1.97029703  1.97029703] and b = [ 193.428       197.02970297  197.02970297]:\n",
      "[ 0.02880658  0.01        0.01      ]\n"
     ]
    }
   ],
   "source": [
    "# now compute a and b for each proposed haplotype\n",
    "a_matrix = []\n",
    "b_matrix = []\n",
    "for k_i, l_i in zip(all_k, all_l):\n",
    "    # calculate and ref as before\n",
    "    alt = (k * syn_alt).sum(axis=1) * 1.0 / k_i\n",
    "    ref = (l * syn_ref).sum(axis=1) * 1.0 / l_i\n",
    "    # need to handle the case where k_i is 0 or l_i is 0\n",
    "    for i, (x, y) in enumerate(zip(alt, ref)):\n",
    "        if np.isinf(x):\n",
    "            alt[i] = 0.01 * y\n",
    "        elif np.isinf(y):\n",
    "            ref[i] = 0.01 * x\n",
    "        # k_i and l_i should never be 0 at the same time\n",
    "        assert not np.isinf(alt[i])\n",
    "    u = alt / (alt + ref)\n",
    "    a = u * (tot - 1)\n",
    "    b = (1 - u) * (tot - 1)\n",
    "    print 'alt/ref ratio for a = {} and b = {}:\\n{}'.format(a, b, alt / ref)\n",
    "    a_matrix.append(a)\n",
    "    b_matrix.append(b)\n",
    "    \n",
    "a_matrix = np.array(a_matrix)\n",
    "b_matrix = np.array(b_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 987,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# score these matrices\n",
    "r_values = []\n",
    "for a, b in zip(a_matrix, b_matrix):\n",
    "    r_values.append(np.sum(betaln(m + a, n + b) - betaln(a, b)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 988,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log odds: -133.20237652\n",
      "\n",
      "results: \n",
      "NAB: 1\n",
      "NC: 2\n",
      "NAB NC ND NN\n",
      "top 10 hits:\n",
      "1: [array([1, 2]), 1, -133.20237652046524]\n",
      "2: [array([2, 1]), 2, -143.11191242136056]\n",
      "3: [array([0, 3]), 0, -143.3971861547783]\n",
      "4: [array([3, 0]), 3, -173.58599608433849]\n"
     ]
    }
   ],
   "source": [
    "# figure out which one was the best scoring\n",
    "r_map = {i: x for i, x in enumerate(r_values)}\n",
    "best_index, score = sorted(r_map.iteritems(), key=lambda x: x[1])[-1]\n",
    "best_haps = C[best_index]\n",
    "ordered = sorted(r_map.iteritems(), key=lambda x: x[1])[-10:][::-1]\n",
    "print 'log odds: {}'.format(score)\n",
    "print ''\n",
    "print 'results: '\n",
    "for x, y in zip(filtered_sun_df.columns[1:], best_haps):\n",
    "    if y > 0:\n",
    "        print '{}: {}'.format(x, y)\n",
    "\n",
    "print ' '.join(filtered_sun_df.columns[1:])\n",
    "print 'top 10 hits:'\n",
    "for i, x in enumerate([[C[pos], pos, val] for pos, val in ordered], 1):\n",
    "    print '{}: {}'.format(i, x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1046,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# now let's scale this to 100 synthetic genomes, with 100 coverage, across our real feature set\n",
    "syn_k = []\n",
    "syn_l = []\n",
    "syn_alt = []\n",
    "syn_ref = []\n",
    "target_coverage = 100\n",
    "num_genomes = 100\n",
    "for _, s in filtered_sun_df.iterrows():\n",
    "    num_alt = 4 * s.NAB + 2 * s.NC + 2 * s.ND + 2 * s.NN\n",
    "    num_ref = 10 - num_alt\n",
    "    syn_k.append([num_alt] * num_genomes)\n",
    "    syn_l.append([num_ref] * num_genomes)\n",
    "    tmp_alt = target_coverage * 1.0 * num_alt / 10\n",
    "    syn_alt.append([tmp_alt] * num_genomes)\n",
    "    syn_ref.append([target_coverage - tmp_alt] * num_genomes)\n",
    "\n",
    "syn_k = np.array(syn_k).astype(float)\n",
    "syn_l = np.array(syn_l).astype(float)\n",
    "syn_alt = np.array(syn_alt).astype(float)\n",
    "syn_ref = np.array(syn_ref).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1047,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first 10 proposed haplotypes:\n",
      "[[ 0.  0.  3.  5.]\n",
      " [ 0.  0.  4.  4.]\n",
      " [ 0.  0.  4.  5.]\n",
      " [ 0.  0.  5.  3.]\n",
      " [ 0.  0.  5.  4.]\n",
      " [ 0.  0.  5.  5.]\n",
      " [ 0.  1.  2.  5.]\n",
      " [ 0.  1.  3.  4.]\n",
      " [ 0.  1.  3.  5.]\n",
      " [ 0.  1.  4.  3.]]\n"
     ]
    }
   ],
   "source": [
    "# allow anywhere from 8 to 12 haplotypes\n",
    "min_n = 8\n",
    "max_n = 12\n",
    "\n",
    "# range of possible genotypes\n",
    "genotypes = range(0, 6)  # [0, 1, 2, 3, 4, 5]\n",
    "\n",
    "# number of columns\n",
    "num_paratypes = 4\n",
    "r = []\n",
    "for i in itertools.product(genotypes, repeat=num_paratypes):\n",
    "    if min_n <= np.sum(i) <= max_n:\n",
    "        r.append(i)\n",
    "\n",
    "C = np.array(r).astype(float)\n",
    "print 'first 10 proposed haplotypes:'\n",
    "print C[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1048,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_k[0][:10]: [ 5.  3.  5.  5.  5.  3.  8.  8.  8.  0.]\n",
      "all_l[0][:10]: [ 3.  5.  3.  3.  3.  5.  0.  0.  0.  8.]\n"
     ]
    }
   ],
   "source": [
    "f = filtered_sun_df[['NAB', 'NC', 'ND', 'NN']]\n",
    "all_k = np.dot(C, f.T)\n",
    "\n",
    "# now we can't just subtract 10, because the total number of paratypes at each proposed genotype changes\n",
    "num_genotypes = C.sum(axis=1)\n",
    "all_l = (num_genotypes - all_k.T).T\n",
    "\n",
    "print 'all_k[0][:10]: {}'.format(all_k[0][:10])\n",
    "\n",
    "print 'all_l[0][:10]: {}'.format(all_l[0][:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1049,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000.0\n"
     ]
    }
   ],
   "source": [
    "#precompute tot\n",
    "tot = np.nansum(syn_alt, axis=1) + np.nansum(syn_ref, axis=1)\n",
    "print tot[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1051,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# now compute a and b for each proposed haplotype\n",
    "a_matrix = []\n",
    "b_matrix = []\n",
    "for k_i, l_i in zip(all_k, all_l):\n",
    "    # calculate and ref as before\n",
    "    alt = (syn_k * syn_alt).sum(axis=1) * 1.0 / k_i\n",
    "    ref = (syn_l * syn_ref).sum(axis=1) * 1.0 / l_i\n",
    "    # need to handle the case where k_i is 0 or l_i is 0\n",
    "    for i, (x, y) in enumerate(zip(alt, ref)):\n",
    "        if np.isinf(x):\n",
    "            alt[i] = 0.01 * y\n",
    "        elif np.isinf(y):\n",
    "            ref[i] = 0.01 * x\n",
    "        # k_i and l_i should never be 0 at the same time\n",
    "        assert not np.isinf(alt[i])\n",
    "    u = alt / (alt + ref)\n",
    "    a = u * (tot - 1)\n",
    "    b = (1 - u) * (tot - 1)\n",
    "    a_matrix.append(a)\n",
    "    b_matrix.append(b)\n",
    "    \n",
    "a_matrix = np.array(a_matrix)\n",
    "b_matrix = np.array(b_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1057,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log odds: -51185.8148424\n",
      "\n",
      "results: \n",
      "NAB: 4.0\n",
      "NC: 2.0\n",
      "ND: 2.0\n",
      "NN: 2.0\n",
      "NAB NC ND NN\n",
      "top 10 hits:\n",
      "1: [array([ 4.,  2.,  2.,  2.]), 521, -51185.814842386753]\n",
      "2: [array([ 5.,  2.,  2.,  2.]), 637, -51414.567363092057]\n",
      "3: [array([ 5.,  2.,  3.,  2.]), 641, -51428.771870830256]\n",
      "4: [array([ 5.,  2.,  2.,  3.]), 638, -51443.314342446174]\n",
      "5: [array([ 3.,  2.,  2.,  2.]), 389, -51531.480063198112]\n",
      "6: [array([ 4.,  2.,  3.,  2.]), 526, -51545.330390295094]\n",
      "7: [array([ 4.,  3.,  2.,  2.]), 545, -51557.311197329982]\n",
      "8: [array([ 4.,  2.,  2.,  3.]), 522, -51600.629128480788]\n",
      "9: [array([ 5.,  3.,  2.,  2.]), 656, -51631.923060585381]\n",
      "10: [array([ 4.,  3.,  3.,  2.]), 549, -51663.076355431651]\n"
     ]
    }
   ],
   "source": [
    "# score these matrices vs. synthetic data\n",
    "# synthetic data is the same as training data\n",
    "\n",
    "m = syn_alt.T[0]\n",
    "n = syn_ref.T[0]\n",
    "\n",
    "r_values = []\n",
    "for a, b in zip(a_matrix, b_matrix):\n",
    "    r_values.append(np.sum(betaln(m + a, n + b) - betaln(a, b)))\n",
    "    \n",
    "# figure out which one was the best scoring\n",
    "r_map = {i: x for i, x in enumerate(r_values)}\n",
    "best_index, score = sorted(r_map.iteritems(), key=lambda x: x[1])[-1]\n",
    "best_haps = C[best_index]\n",
    "ordered = sorted(r_map.iteritems(), key=lambda x: x[1])[-10:][::-1]\n",
    "print 'log odds: {}'.format(score)\n",
    "print ''\n",
    "print 'results: '\n",
    "for x, y in zip(filtered_sun_df.columns[1:], best_haps):\n",
    "    if y > 0:\n",
    "        print '{}: {}'.format(x, y)\n",
    "\n",
    "print ' '.join(filtered_sun_df.columns[1:])\n",
    "print 'top 10 hits:'\n",
    "for i, x in enumerate([[C[pos], pos, val] for pos, val in ordered], 1):\n",
    "    print '{}: {}'.format(i, x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
